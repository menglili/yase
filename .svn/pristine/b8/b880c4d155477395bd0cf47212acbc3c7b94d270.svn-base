package edu.upenn.cis455.YASE.indexer;

import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.LongWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapred.*;

import java.io.File;
import java.io.IOException;
import java.net.MalformedURLException;
import java.net.URL;
import java.util.Comparator;
import java.util.HashMap;
import java.util.Iterator;
import java.util.PriorityQueue;

public class InvertIndex {
    public static class Map extends MapReduceBase implements
            Mapper<LongWritable, Text, Text, Text> {
        private final Text word = new Text();
        private final Text url_tf = new Text();

        @Override
        public void map(LongWritable key, Text value,
                        OutputCollector<Text, Text> output, Reporter reporter)
                throws IOException {

            String line = value.toString();
            String[] splitter = line.split("\t");

            if (splitter.length != 4) {
                // System.err.println("error: line read:" + line + " ");
                return;
            }

            // set to lowercase
            for (int i = 0; i < splitter.length; i++)
                splitter[i] = splitter[i].toLowerCase();

            // get params
            String urlString = splitter[0];
            String titleString = splitter[2];
            String wordsString = splitter[3];

            //make url appear multiple times to increase its TF
            String[] urlKeywordsStringArray = separateURLKeywords(urlString);
            String multipleURLKeywords = "";
            if (urlKeywordsStringArray != null) {
                for (String s : urlKeywordsStringArray) {
                    multipleURLKeywords += " " + repeatString(s, 5);
                }
            }

            // make title appear multiple times to increase its TF
            String multipleTitles = repeatString(titleString, 10);

            // merge title with words
            String allWords = multipleURLKeywords + multipleTitles + " " + wordsString;

            // compute TF
            HashMap<String, Integer> urlTFMap = new HashMap<String, Integer>();
            int dataLength = 0;
            for (String wordString : allWords.split(" ")) {

                //check alphanumeric
                if (!isValidString(wordString)) {
                    System.err.println("Error: not alphanumeric: " + wordString);
                    continue;
                }
                if (urlTFMap.keySet().contains(wordString)) {
                    int tf = urlTFMap.get(wordString);
                    tf++;
                    urlTFMap.put(wordString, tf); // update tf
                } else { // if new
                    urlTFMap.put(wordString, 1);
                }
                dataLength++;
            }

            // compute TF2
            for (String w : urlTFMap.keySet()) {
                double tf = (double) urlTFMap.get(w);
                double tf2 = tf / java.lang.Math.sqrt(dataLength);
                url_tf.set(urlString + " " + tf2);
                word.set(w);
                output.collect(word, url_tf);
            }

        }

        private String repeatString(String s, int numRepeats) {
            String result = "";
            for (int i = 0; i < numRepeats; i++) {
                result += (" " + s);
            }
            result = result.trim();
            return result;
        }

        private String[] separateURLKeywords(String urlString) {

            String[] stringArray = null;
            try {
                URL url = new URL(urlString);
                String s = url.getHost();
                s = s.replaceFirst("http://", "");
                int index = s.lastIndexOf(".");
                s = s.substring(0, index);
                if (s.startsWith("www.")) {
                    s = s.substring(4);

                }
                stringArray = s.split("\\.");


            } catch (MalformedURLException e) {
                System.err.println("URL format error: " + urlString);

            }

            return stringArray;
        }

        private static boolean isValidString(final CharSequence cs) {
            if (cs == null) {
                return false;
            }
            final int sz = cs.length();
            for (int i = 0; i < sz; i++) {
                if (!Character.isLetterOrDigit(cs.charAt(i)) && cs.charAt(i) != '-' && cs.charAt(i) != '_' && cs.charAt(i) != '.' && cs.charAt(i) != '\'') {
                    return false;
                }
            }
            return true;
        }
    }

    public static class Reduce extends MapReduceBase implements
            Reducer<Text, Text, Text, Text> {
        private final Text invertedList = new Text();

        @Override
        public void reduce(Text key, Iterator<Text> values,
                           OutputCollector<Text, Text> output, Reporter reporter)
                throws IOException {

            String contentList = "";
            PriorityQueue<URLTF> urlTFQueue = new PriorityQueue<URLTF>(100,
                    new TFComparator());

            while (values.hasNext()) {
                String urlString = values.next().toString();
                String[] strings = urlString.split(" ");
                String url = strings[0];
                double tf = Double.parseDouble(strings[1]);

                urlTFQueue.add(new URLTF(url, tf));
            }

            while (true) {
                URLTF urltf = urlTFQueue.poll();
                if (urltf == null)
                    break;
                contentList += "\t" + urltf.getUrl() + " " + urltf.getTf();
            }

            // remove first \t
            contentList = contentList.substring(1);

            invertedList.set(contentList);
            output.collect(key, invertedList);
        }

        static class TFComparator implements Comparator<URLTF> {

            @Override
            public int compare(URLTF o1, URLTF o2) {
                return Double.compare(o2.getTf(), o1.getTf());
            }
        }

        private class URLTF {

            private String url;
            private double tf;

            public URLTF(String url, double tf) {
                this.tf = tf;
                this.url = url;
            }

            public double getTf() {
                return tf;
            }

            public String getUrl() {
                return url;
            }

            @Override
            public String toString() {
                return String.format("{url=%s, tf=%s}", url, tf);
            }

        }
    }

    public static void main(String[] args) throws Exception {
        JobConf conf = new JobConf(InvertIndex.class);
        conf.setJobName("InvertIndex");

        conf.setOutputKeyClass(Text.class);
        conf.setOutputValueClass(Text.class);

        conf.setMapperClass(Map.class);
        conf.setReducerClass(Reduce.class);

        conf.setInputFormat(TextInputFormat.class);
        conf.setOutputFormat(TextOutputFormat.class);

        FileInputFormat.setInputPaths(conf, new Path(args[0]));
        FileOutputFormat.setOutputPath(conf, new Path(args[1]));

        File outputFolder = new File(args[1]);
        File[] files = outputFolder.listFiles();

        if (outputFolder.exists()) {
            for (File file : files) {
                file.delete();
            }
            outputFolder.delete();
        }

        JobClient.runJob(conf);
    }
}